{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5db123ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Embedding, Dense, Flatten\n",
    "from keras.layers import LSTM, Dropout\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2d082c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(filename, objeto):\n",
    "    outfile = open(filename,'wb')\n",
    "    pickle.dump(objeto,outfile)\n",
    "    outfile.close()\n",
    "\n",
    "def load_pickle(filename):\n",
    "    infile = open(filename,'rb')\n",
    "    objeto = pickle.load(infile)\n",
    "    infile.close()\n",
    "    return objeto\n",
    "\n",
    "def create_model(vocabulary_size, seq_len):  \n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(maxlen,)))\n",
    "    model.add(Embedding(vocabulary_size, seq_len, weights=[embedding_weights], input_length=maxlen))\n",
    "    model.add(LSTM(64, return_sequences=True, activation='relu'))\n",
    "    #model.add(LSTM(64, return_sequences=True, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    #model.add(Dense(256, activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_of_classes,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1aefae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "681b5a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artikel</th>\n",
       "      <th>wort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Die</td>\n",
       "      <td>Zeit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Der</td>\n",
       "      <td>Man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Die</td>\n",
       "      <td>Hand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Die</td>\n",
       "      <td>Tag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Der</td>\n",
       "      <td>Weg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2605</th>\n",
       "      <td>Die</td>\n",
       "      <td>Haupt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2606</th>\n",
       "      <td>Das</td>\n",
       "      <td>Erlebnis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>Der</td>\n",
       "      <td>Datensatz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>Das</td>\n",
       "      <td>Geheimnis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>Der</td>\n",
       "      <td>Honig</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2610 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     artikel       wort\n",
       "0        Die       Zeit\n",
       "1        Der        Man\n",
       "2        Die       Hand\n",
       "3        Die        Tag\n",
       "4        Der        Weg\n",
       "...      ...        ...\n",
       "2605     Die      Haupt\n",
       "2606     Das   Erlebnis\n",
       "2607     Der  Datensatz\n",
       "2608     Das  Geheimnis\n",
       "2609     Der      Honig\n",
       "\n",
       "[2610 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = load_pickle('Worter.p')\n",
    "\n",
    "#Extract words and articles\n",
    "artikels = []\n",
    "worter = []\n",
    "\n",
    "for key, wort in base.items():\n",
    "    artikels.append(wort['Gender'])\n",
    "    worter.append(wort['ORTH'])\n",
    "    \n",
    "df = pd.DataFrame({'artikel': artikels,'wort': worter})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "992162fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erick\\AppData\\Local\\Temp\\ipykernel_9104\\4031407106.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['wort'] = df['wort'].str.lower()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artikel</th>\n",
       "      <th>wort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Die</td>\n",
       "      <td>zeit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Der</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Die</td>\n",
       "      <td>hand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Die</td>\n",
       "      <td>tag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Der</td>\n",
       "      <td>weg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2605</th>\n",
       "      <td>Die</td>\n",
       "      <td>haupt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2606</th>\n",
       "      <td>Das</td>\n",
       "      <td>erlebnis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>Der</td>\n",
       "      <td>datensatz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>Das</td>\n",
       "      <td>geheimnis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>Der</td>\n",
       "      <td>honig</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2590 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     artikel       wort\n",
       "0        Die       zeit\n",
       "1        Der        man\n",
       "2        Die       hand\n",
       "3        Die        tag\n",
       "4        Der        weg\n",
       "...      ...        ...\n",
       "2605     Die      haupt\n",
       "2606     Das   erlebnis\n",
       "2607     Der  datensatz\n",
       "2608     Das  geheimnis\n",
       "2609     Der      honig\n",
       "\n",
       "[2590 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cleaning Dataset\n",
    "df = df.loc[(df.loc[:,'artikel'] == 'Der') | \n",
    "            (df.loc[:,'artikel'] == 'Die') |\n",
    "            (df.loc[:,'artikel'] == 'Das'), :] \n",
    "\n",
    "df['wort'] = df['wort'].str.lower()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcef0142",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split train and test\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "train_texts = train_df['wort'].values \n",
    "test_texts = test_df['wort'].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb585a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'UNK': 1, 'e': 2, 'n': 3, 'r': 4, 't': 5, 'a': 6, 'i': 7, 's': 8, 'l': 9, 'h': 10, 'u': 11, 'g': 12, 'o': 13, 'c': 14, 'k': 15, 'm': 16, 'f': 17, 'b': 18, 'd': 19, 'p': 20, 'z': 21, 'w': 22, 'v': 23, 'ü': 24, 'ä': 25, 'ö': 26, 'j': 27, 'y': 28, 'ß': 29, 'x': 30, 'q': 31}\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer\n",
    "tk = Tokenizer(num_words=None, char_level=True, oov_token='UNK')\n",
    "tk.fit_on_texts(train_texts)\n",
    "print(tk.word_index)\n",
    "\n",
    "# Convert string to index \n",
    "train_sequences = tk.texts_to_sequences(train_texts)\n",
    "test_texts = tk.texts_to_sequences(test_texts)\n",
    "\n",
    "# Padding\n",
    "train_data = pad_sequences(train_sequences, maxlen=maxlen, padding='pre')\n",
    "test_data = pad_sequences(test_texts, maxlen=maxlen, padding='pre')\n",
    "\n",
    "# Convert to numpy array\n",
    "train_data = np.array(train_data, dtype='float32')\n",
    "test_data = np.array(test_data, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54324c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = train_df['artikel'].values\n",
    "test_classes = test_df['artikel'].values\n",
    "\n",
    "le = LabelEncoder()\n",
    "le = le.fit(df['artikel'])\n",
    "le.classes_\n",
    "\n",
    "train_classes = le.transform(train_classes)\n",
    "test_classes = le.transform(test_classes)\n",
    "\n",
    "train_classes = to_categorical(train_classes)\n",
    "test_classes = to_categorical(test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32b6c935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 25, 31)            992       \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 25, 64)            24576     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               409856    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 436195 (1.66 MB)\n",
      "Trainable params: 436195 (1.66 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "65/65 [==============================] - 3s 18ms/step - loss: 1.0522 - accuracy: 0.4406 - val_loss: 1.0318 - val_accuracy: 0.5618 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "65/65 [==============================] - 1s 14ms/step - loss: 0.9662 - accuracy: 0.5487 - val_loss: 0.9825 - val_accuracy: 0.5328 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "65/65 [==============================] - 1s 14ms/step - loss: 0.8709 - accuracy: 0.6038 - val_loss: 0.8944 - val_accuracy: 0.6062 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "65/65 [==============================] - 1s 14ms/step - loss: 0.8520 - accuracy: 0.6240 - val_loss: 0.8915 - val_accuracy: 0.5869 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.8116 - accuracy: 0.6404 - val_loss: 0.8882 - val_accuracy: 0.5985 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "65/65 [==============================] - 1s 14ms/step - loss: 0.7824 - accuracy: 0.6501 - val_loss: 0.8758 - val_accuracy: 0.6236 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.7620 - accuracy: 0.6699 - val_loss: 0.8899 - val_accuracy: 0.6216 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 0.7342 - accuracy: 0.6747 - val_loss: 0.8718 - val_accuracy: 0.6062 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.7076 - accuracy: 0.7017 - val_loss: 0.8505 - val_accuracy: 0.6448 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "65/65 [==============================] - 1s 13ms/step - loss: 0.6977 - accuracy: 0.7046 - val_loss: 0.8531 - val_accuracy: 0.6544 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "65/65 [==============================] - 1s 14ms/step - loss: 0.6645 - accuracy: 0.7080 - val_loss: 0.8581 - val_accuracy: 0.6486 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "65/65 [==============================] - 1s 14ms/step - loss: 0.6404 - accuracy: 0.7167 - val_loss: 0.9064 - val_accuracy: 0.6544 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "65/65 [==============================] - 1s 14ms/step - loss: 0.6372 - accuracy: 0.7278 - val_loss: 0.8711 - val_accuracy: 0.6448 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "65/65 [==============================] - 1s 14ms/step - loss: 0.6048 - accuracy: 0.7379 - val_loss: 0.9105 - val_accuracy: 0.6602 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "65/65 [==============================] - 1s 14ms/step - loss: 0.5752 - accuracy: 0.7500 - val_loss: 0.9198 - val_accuracy: 0.6467 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "65/65 [==============================] - 1s 14ms/step - loss: 0.5647 - accuracy: 0.7592 - val_loss: 0.9015 - val_accuracy: 0.6506 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "65/65 [==============================] - 1s 13ms/step - loss: 0.5392 - accuracy: 0.7736 - val_loss: 0.9647 - val_accuracy: 0.6506 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "65/65 [==============================] - 1s 14ms/step - loss: 0.5245 - accuracy: 0.7785 - val_loss: 0.9629 - val_accuracy: 0.6409 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "65/65 [==============================] - 1s 13ms/step - loss: 0.4955 - accuracy: 0.7862 - val_loss: 1.0103 - val_accuracy: 0.6351 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "65/65 [==============================] - 1s 14ms/step - loss: 0.4810 - accuracy: 0.7987 - val_loss: 0.9996 - val_accuracy: 0.6564 - lr: 0.0010\n",
      "Epoch 21/30\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.4650 - accuracy: 0.8103 - val_loss: 1.0582 - val_accuracy: 0.6409 - lr: 0.0010\n",
      "Epoch 22/30\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.4453 - accuracy: 0.8108 - val_loss: 1.1342 - val_accuracy: 0.6390 - lr: 0.0010\n",
      "Epoch 23/30\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.4263 - accuracy: 0.8209 - val_loss: 1.0693 - val_accuracy: 0.6178 - lr: 0.0010\n",
      "Epoch 24/30\n",
      "65/65 [==============================] - 1s 17ms/step - loss: 0.3925 - accuracy: 0.8407 - val_loss: 1.2495 - val_accuracy: 0.6409 - lr: 0.0010\n",
      "Epoch 25/30\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 0.4032 - accuracy: 0.8359 - val_loss: 1.1285 - val_accuracy: 0.6448 - lr: 0.0010\n",
      "Epoch 26/30\n",
      "65/65 [==============================] - 1s 17ms/step - loss: 0.3761 - accuracy: 0.8422 - val_loss: 1.2310 - val_accuracy: 0.6313 - lr: 0.0010\n",
      "Epoch 27/30\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.3503 - accuracy: 0.8581 - val_loss: 1.2656 - val_accuracy: 0.6332 - lr: 0.0010\n",
      "Epoch 28/30\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.3266 - accuracy: 0.8711 - val_loss: 1.3453 - val_accuracy: 0.6351 - lr: 0.0010\n",
      "Epoch 29/30\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.3091 - accuracy: 0.8779 - val_loss: 1.4156 - val_accuracy: 0.6429 - lr: 0.0010\n",
      "Epoch 30/30\n",
      "65/65 [==============================] - 1s 14ms/step - loss: 0.2803 - accuracy: 0.8837 - val_loss: 1.4785 - val_accuracy: 0.6332 - lr: 0.0010\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.4785 - accuracy: 0.6332\n",
      "Test set\n",
      "  Loss: 1.478\n",
      "  Accuracy: 0.633\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tk.word_index)\n",
    "\n",
    "#Setar onehot para cada letra\n",
    "embedding_weights = []\n",
    "embedding_weights.append(np.zeros(vocab_size))\n",
    "for char, i in tk.word_index.items():\n",
    "    onehot = np.zeros(vocab_size)\n",
    "    onehot[i-1] = 1\n",
    "    embedding_weights.append(onehot)\n",
    "embedding_weights = np.array(embedding_weights)\n",
    "\n",
    "# parameter \n",
    "embedding_size = 31\n",
    "num_of_classes = 3\n",
    "\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor= 'loss', patience = 10, verbose = 1, restore_best_weights=True)\n",
    "rlr = ReduceLROnPlateau(monitor='loss', factor= 0.1, patience= 3, verbose=1)\n",
    "\n",
    "model = create_model(vocab_size+1, embedding_size)\n",
    "model.summary()\n",
    "\n",
    "#Treinamento do modelo\n",
    "history = model.fit(train_data, train_classes,\n",
    "                    validation_data=(test_data, test_classes),\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    verbose=1,\n",
    "                    callbacks=[es, rlr])\n",
    "\n",
    "#model.load_weights('pesos.h5')\n",
    "\n",
    "accuracy = model.evaluate(test_data,test_classes)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accuracy[0],accuracy[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84980e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wort</th>\n",
       "      <th>Real Artikel</th>\n",
       "      <th>Predicted Artikel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>schal</td>\n",
       "      <td>Der</td>\n",
       "      <td>Das</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iris</td>\n",
       "      <td>Die</td>\n",
       "      <td>Die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gegenleistung</td>\n",
       "      <td>Die</td>\n",
       "      <td>Die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zeitung</td>\n",
       "      <td>Die</td>\n",
       "      <td>Die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>karriere</td>\n",
       "      <td>Die</td>\n",
       "      <td>Die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>familie</td>\n",
       "      <td>Die</td>\n",
       "      <td>Die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>kran</td>\n",
       "      <td>Der</td>\n",
       "      <td>Der</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>ausrüstung</td>\n",
       "      <td>Die</td>\n",
       "      <td>Die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>ende</td>\n",
       "      <td>Das</td>\n",
       "      <td>Die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>dieb</td>\n",
       "      <td>Der</td>\n",
       "      <td>Das</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>518 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Wort Real Artikel Predicted Artikel\n",
       "0            schal          Der               Das\n",
       "1             iris          Die               Die\n",
       "2    gegenleistung          Die               Die\n",
       "3          zeitung          Die               Die\n",
       "4         karriere          Die               Die\n",
       "..             ...          ...               ...\n",
       "513        familie          Die               Die\n",
       "514           kran          Der               Der\n",
       "515     ausrüstung          Die               Die\n",
       "516           ende          Das               Die\n",
       "517           dieb          Der               Das\n",
       "\n",
       "[518 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(test_data)\n",
    "predictions = [np.argmax(x) for x in predictions]\n",
    "predictions = le.inverse_transform(predictions)\n",
    "results = pd.DataFrame({'Wort': test_df['wort'].values, 'Real Artikel': test_df['artikel'].values, 'Predicted Artikel': predictions})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a42ca7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_der = results.loc[results['Real Artikel'] == 'Der']\n",
    "results_die = results.loc[results['Real Artikel'] == 'Die']\n",
    "results_das = results.loc[results['Real Artikel'] == 'Das']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b4e5354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6235955056179775"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_der = accuracy_score(results_der['Real Artikel'], results_der['Predicted Artikel'])\n",
    "accuracy_der\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2e42df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7370689655172413"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_die = accuracy_score(results_die['Real Artikel'], results_die['Predicted Artikel'])\n",
    "accuracy_die"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2af7cb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42592592592592593"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_das = accuracy_score(results_das['Real Artikel'], results_das['Predicted Artikel'])\n",
    "accuracy_das"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dbe5bac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \"er\": 0.62\n",
      "Accuracy: \"en\": 0.46\n",
      "Accuracy: \"keit\": 1.0\n",
      "Accuracy: \"heit\": 0.75\n",
      "Accuracy: \"tät\": 1.0\n",
      "Accuracy: \"e\": 0.77\n",
      "Accuracy: \"chen\": 0.75\n",
      "Accuracy: \"a\": 0.8\n"
     ]
    }
   ],
   "source": [
    "def custom_ending(wort_ending):\n",
    "    result_textpart = results.loc[results['Wort'].str.endswith(wort_ending)]\n",
    "    accuracy_textpart = accuracy_score(result_textpart['Real Artikel'], result_textpart['Predicted Artikel'])\n",
    "    print(f'Accuracy: \"{wort_ending}\": {round(accuracy_textpart,2)}')\n",
    "\n",
    "custom_ending('er') #Der\n",
    "custom_ending('en') #Der\n",
    "custom_ending('keit') #Die\n",
    "custom_ending('heit') #Die\n",
    "custom_ending('tät') #Die\n",
    "custom_ending('e') #Die\n",
    "custom_ending('chen') #Das\n",
    "custom_ending('a') #Das"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a11c7d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
